---
layout: post
title: "Apache Kafka event stream with workflows"
subtitle: "Employ workflows to manage your event streams"
date: 2021-11-29 15:45:00 +0100
background: '/img/posts/17.jpg'
---

<h2 class="section-heading">Apache Kafka event streams consumed by workflows</h2>

<p>
  An inspiration for this blog post is another blog post by Piotr Minkowski that perfectly
  introduced <a href="https://piotrminkowski.com/2021/11/24/kafka-streams-with-quarkus/">Kafka Streams with Quarkus</a>.
  This triggered a thought - can workflows be used as an alternative to Kafka Streams to process multiple
  event streams (merge them and process various events streams with some correlation logic)?
</p>

<p><i>
As a desclaimer - this blog post is to not put workflows as replacement of Kafka Streams but to showcase
capabilities that workflows have in terms of event streams.
</i></p>


<p>
  First of all, please have a read of Piotr's blog post first to understand the use case as this article
  heavily relies on that understanding. But to set the stage quickly let me quote Piotr's first paragraph of
  architecture:
</p>

<p><i>
"In our case, there are two incoming streams of events. Both of them represent incoming orders. These orders are generated by the order-service application.
It sends buy orders to the orders.buy topic and sell orders to the orders.sell topic. Then, the stock-service application receives and handles incoming events.
In the first step, it needs to change the key of each message from the orderId to the productId. Thatâ€™s because it has to join orders from different topics
related to the same product in order to execute transactions. Finally, the transaction price is an average of sale and buy prices."
</i></p>

<h2 class="section-heading">Source code</h2>

<p>
Source code of the services described in this article can be found

<ul>
  <li><a href="https://github.com/piomin/sample-quarkus-kafka-streams">Kafka Streams based example</a></li>
  <li><a href="https://github.com/mswiderski/sample-quarkus-kafka-streams">Workflow based example</a></li>
</ul>
</p>

<h2 class="section-heading">Let's put workflow instead of Kafka Streams as StockService</h2>

<p>
  In the original example stock service was built around Kafka Streams, this article introduces workflow to take that part.
</p>

<img class="img-fluid" src="/img/posts/17_1.png" alt="Workflow definition of stock service">
<span class="caption text-muted">Workflow definition of stock service.</span>

<p>
Important aspect to understand is how workflows can merge incoming events from two streams

<ul>
  <li>orders.buy</li>
  <li>orders.sell</li>
</ul>

The events on both streams carry order information where the common part is <code>productId</code>. Product id will guide
the business logic to match sell orders with buy orders to generate transaction. This is what Kafka Streams was used for
in the original example.
</p>

<p>
  And that is what workflows can be used for. To receive events from different streams, directly correlate them based on
  <code>productId</code> and process to generate transactions. The important part here is that there will be single workflow instance that will process all orders
  (both buy and sell) for the same product id. This allows us to handle the use case for analitics around the transactions.
</p>

<h2 class="section-heading">How things are correlated (merge sell and buy orders)?</h2>

<p>
  As can be seen on the workflow diagram, it has two entry points (so called message start events). These two are configured with the
  event streams - <code>orders.buy</code> and <code>orders.sell</code>. Each of these message start events uses
  <code>correlationExpression</code> to find out what workflow instance should handle given event.
</p>

<img class="img-fluid" src="/img/posts/17_2.png" alt="Message correlation expression">
<span class="caption text-muted">Message correlation expression and topic name.</span>

<p>
  In this case <code>correlationExpression</code> is set to <code>getProductId(eventData)</code>. This will be evaluated everytime new event is
  received, <code>eventData</code> corresponds to variable that will hold the event payload and by that will give access to product id. In this case
  <code>getProductId</code> method is a reference to a function that is defined like below.
</p>

<span class="caption text-muted">Correlation expression as function</span>
<pre><code class="language-java">
  public class StockFunctions implements Functions {

      public static String getProductId(Order eventData) {

          return String.valueOf(eventData.getProductId());
      }
  }
</code></pre>

<p><i>
Functions in automatiko are just public static methods on a class that implements <code>io.automatiko.engine.api.Functions</code>. All these methods are then
available for correlation expressions, tags, data mappings, script tasks etc.
</i></p>

<p>
  In addition, to make this work as expected - that is to process events to either start new instance or call existing instance based on incoming events
  another setting is required on these start events.
</p>

<img class="img-fluid" src="/img/posts/17_3.png" alt="Allow to signal on start">
<span class="caption text-muted">Start event to allow signal via start events.</span>

<p>
  Those that know BPMN execution semantics can directly point out that start events will always trigger new instance and thus makes it
  impossible to correlate to cover this use case. This is exactly why Automatiko has this extra setting (<code>acceptStartSignal</code>) on the start event that
  instructs the execution that start event can be used as both trigger of new instance (if none exists) or signal exising.
</p>

<h2 class="section-heading">Publishing transactions</h2>

Upon successful match operation a new transaction is created. That transaction is used to calculate totals (described in next section) and finally
published to <code>transactions</code> topic in Apache Kafka. This is done by using message end event that acts in similar way as start event but
produces events instead of consuming them.

<h2 class="section-heading">Analitics</h2>

<p>
  There is additional part of this example that is responsible for analitics - calculate transaction statistics

  <ul>
    <li>total count of transactions</li>
    <li>total amount of transactions</li>
    <li>total product count of transactions</li>
  </ul>
</p>

<p>
  Analitics can be easily accessed via dedicated endpoints that workflows comes with. Workflow definition is named
  <code>stocks</code> and by that this becomes part of the resource endpoint so it can be easily accessed over HTTP

  <code>http://localhost:8080/stocks</code>
</p>
  <pre><code class="language-json">
    [
        {
            "id": "1",
            "metadata": null,
            "total": {
                "amount": 1100,
                "count": 6,
                "productCount": 1240800
            }
        },
        {
            "id": "4",
            "metadata": null,
            "total": {
                "amount": 3300,
                "count": 12,
                "productCount": 5245200
            }
        },
        ...
        {
            "id": "7",
            "metadata": null,
            "total": {
                "amount": 3200,
                "count": 11,
                "productCount": 4188700
            }
        }
    ]
  </code></pre>

<p>
  You can also target single product related information by <code>http://localhost:8080/stocks/1</code>.
</p>

<p>
  On top of that, Automatiko comes with built-in simple management interface that can be used to look at the running instances. To
  access this interface go to <code>http://localhost:8080/management/processes/ui</code>
</p>

<img class="img-fluid" src="/img/posts/17_4.png" alt="Process management UI">
<span class="caption text-muted">Process management UI.</span>

<p>
  Individual instance can be easily viewed by opening details for given row.
</p>

<img class="img-fluid" src="/img/posts/17_5.png" alt="Process management UI - instance details">
<span class="caption text-muted">Process management UI - instance details.</span>

<h2 class="section-heading">Remove outdated orders</h2>

<p>
  Last feature of this example service it to remove outdated orders. As mentioned in the original blog post, orders can be processed only
  when they are not older than 10 seconds. For this exact purpose is the extra workflow fragment (called event subprocess) that will fire off
  every 10 seconds and do the automatic clean up.
</p>

<img class="img-fluid" src="/img/posts/17_6.png" alt="Remove outdated orders on interval">
<span class="caption text-muted">Remove outdated orders on interval.</span>

<h2 class="section-heading">Data classification</h2>

<p>
  One thing that people might wonder about is how is it possible that there are several data objects defined in the workflow

  <ul>
    <li><code>buyOrders</code></li>
    <li><code>sellOrders</code></li>
    <li><code>transaction</code></li>
    <li><code>transactions</code></li>
    <li><code>total</code></li>
  </ul>

  but only <code>total</code> is visible in the service interface as described and shown in the <code>Analitics</code> section.
</p>

<p>
  The answer to this is - use of data object tags. Tags allow to classify data as

  <ul>
    <li>input</li>
    <li>output</li>
    <li>internal</li>
    <li>transient</li>
    <li>and more...</li>
  </ul>

  This drives how does the service interface data model look like and that's why only <code>total</code> is visible as this is the only
  one that is marked as <code>output</code> with tag.
</p>


<h2 class="section-heading">Let's see it in action</h2>

<p>At the end, have a look at a short screencast showing this example in action.</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/FHjaxPyZKSQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<p>
  Thanks for reading and make sure to drop us feedback or ask questions about this article.
</p>

<p>Photographs by <a href="https://unsplash.com/">Unsplash</a>.</p>
